{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcandidate(filepath):\n",
    "    entity = []\n",
    "    with open(filepath) as f:\n",
    "        diclist = json.load(f)['entries']\n",
    "        for dic in diclist:\n",
    "            dic = list(dic.values())[0]\n",
    "            for ops in dic[\"modifiedtripleset\"]:\n",
    "                entity.append(' '.join(ops['subject'].split('_')).replace('\"', ''))\n",
    "                entity.append(' '.join(ops['object'].split('_')).replace('\"', ''))\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(wd):\n",
    "    if random.random() < 0.5:\n",
    "        return choice(allentity), True\n",
    "    else:\n",
    "        return wd, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makenoisy(gold, datadiclist):\n",
    "    noisytext = gold\n",
    "    poslist = [0 for i in range(len(gold.split(' ')))]\n",
    "    # sum = 0\n",
    "    entitys = []\n",
    "    for datadic in datadiclist:\n",
    "        entitys.append(' '.join(datadic['subject'].lower().split('_')))\n",
    "        entitys.append(' '.join(datadic['object'].lower().split('_')))\n",
    "        # print(datadic['subject'].lower())\n",
    "        # print(noisytext)\n",
    "    for entity in entitys:\n",
    "        lis = noisytext.split(entity)\n",
    "        length = len(lis)\n",
    "        tmp = lis[0]\n",
    "        posleft = []\n",
    "        posout = []\n",
    "        id = 0\n",
    "        for wd in lis:\n",
    "            if wd == '':\n",
    "                lens = 0\n",
    "            else:\n",
    "                lens = len(wd.split(' '))\n",
    "            posleft.append(poslist[id: id+len(lens)])\n",
    "            posout.append(poslist[id+len(lens): id+len(lens)+len(entity.split(' '))])\n",
    "            id += len(lens) + len(entity.split(' '))\n",
    "\n",
    "        postmp = posleft[0]\n",
    "        if length > 1:\n",
    "            # sum += 1\n",
    "            for i, (wd, posb, poso) in enumerate(zip(lis, posleft, posout)):\n",
    "                if i > 0:\n",
    "                    ch, wh = change(entity)\n",
    "                    tmp += ch + wd\n",
    "                    if wh:\n",
    "                        postmp += [1 for mm in range(len(ch.split(' ')))] + posb\n",
    "                    else:\n",
    "                        postmp += poso + posb\n",
    "            noisytext = tmp\n",
    "            poslist = postmp\n",
    "\n",
    "\n",
    "    return noisytext, poslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makepseudo(filepath):\n",
    "    with open(filepath) as f:\n",
    "        fsrcdata = open('../pseudo/' + filepath.split('_')[-1].split('.')[0] + '.src.data', 'w')\n",
    "        fsrctext = open('../pseudo/' + filepath.split('_')[-1].split('.')[0] + '.src.text', 'w')\n",
    "        ftgttext = open('../pseudo/' + filepath.split('_')[-1].split('.')[0] + '.tgt.text', 'w')\n",
    "        ftgtpos = open('../pseudo/' + filepath.split('_')[-1].split('.')[0] + '.tgt.pos', 'w')\n",
    "        ftgtedit = open('../pseudo/' + filepath.split('_')[-1].split('.')[0] + '.tgt.edit', 'w')\n",
    "\n",
    "        diclist = json.load(f)['entries']\n",
    "        for dic in diclist:\n",
    "            dic = list(dic.values())[0]\n",
    "            dic.pop('originaltriplesets')\n",
    "            textlist = dic.pop('lexicalisations')\n",
    "            textlist = [x['lex'] for x in textlist]\n",
    "            datastr = '<category> '+dic['category']+' <shape> '+dic['shape']+' <type> '+dic['shape_type']+' <sep>'\n",
    "            for datadic in dic[\"modifiedtripleset\"]:\n",
    "                datastr += ' <s> '+' '.join(datadic['subject'].split('_')).lower()+' <p> '+datadic['property']+' <o> '+' '.join(datadic['object'].split('_')).lower()\n",
    "            for text in textlist:\n",
    "                text = text.lower()\n",
    "                ftgttext.write(text+'\\n')\n",
    "                noisytext, poslist = makenoisy(text, dic[\"modifiedtripleset\"])\n",
    "                fsrctext.write(noisytext + '\\n')\n",
    "                fsrcdata.write(datastr + '\\n')\n",
    "                ftgtpos.write(str(poslist) + '\\n')\n",
    "        ftgttext.close() \n",
    "        fsrcdata.close()\n",
    "        fsrctext.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allentity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allentity=getcandidate('webnlg_release_v2.1_dev.json')\n",
    "# getcandidate('webnlg_release_v2.1_test.json')\n",
    "# getcandidate('webnlg_release_v2.1_train.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "makepseudo('webnlg_release_v2.1_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(allentity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['2702.0',\n",
       " 'Adirondack Regional Airport',\n",
       " '507',\n",
       " 'Adirondack Regional Airport',\n",
       " 'Harrietstown, New York',\n",
       " 'Adolfo Suárez Madrid–Barajas Airport']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "allentity[3:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}